name: Documentation Maintenance

on:
  schedule:
    # Run documentation maintenance tasks weekly on Sunday at 3 AM UTC
    - cron: '0 3 * * 0'
  workflow_dispatch:
    inputs:
      task:
        description: 'Maintenance task to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - cleanup
          - update-index
          - check-orphans
          - generate-stats

jobs:
  documentation-maintenance:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        
    - name: Create maintenance scripts directory
      run: |
        mkdir -p scripts/maintenance
        
    - name: Create documentation cleanup script
      run: |
        cat > scripts/maintenance/cleanup-docs.js << 'EOF'
        #!/usr/bin/env node
        
        const fs = require('fs');
        const path = require('path');
        
        /**
         * Documentation Cleanup Script
         * 
         * This script performs routine maintenance tasks on the documentation
         */
        
        function cleanupDocumentation() {
          console.log('ğŸ§¹ Starting documentation cleanup...');
          
          // Tasks to perform
          const tasks = [
            'removeEmptyFiles',
            'standardizeLineEndings',
            'removeTrailingWhitespace',
            'fixDuplicateHeaders',
            'updateLastModified'
          ];
          
          for (const task of tasks) {
            console.log(`ğŸ“ Running task: ${task}`);
            try {
              switch (task) {
                case 'removeEmptyFiles':
                  removeEmptyFiles();
                  break;
                case 'standardizeLineEndings':
                  standardizeLineEndings();
                  break;
                case 'removeTrailingWhitespace':
                  removeTrailingWhitespace();
                  break;
                case 'fixDuplicateHeaders':
                  fixDuplicateHeaders();
                  break;
                case 'updateLastModified':
                  updateLastModified();
                  break;
              }
              console.log(`âœ… Completed: ${task}`);
            } catch (error) {
              console.error(`âŒ Failed: ${task}`, error.message);
            }
          }
          
          console.log('ğŸ‰ Documentation cleanup completed!');
        }
        
        function removeEmptyFiles() {
          const docsDir = 'Docs';
          if (!fs.existsSync(docsDir)) return;
          
          const files = fs.readdirSync(docsDir, { recursive: true });
          let removed = 0;
          
          for (const file of files) {
            const filePath = path.join(docsDir, file);
            if (fs.statSync(filePath).isFile() && file.endsWith('.md')) {
              const content = fs.readFileSync(filePath, 'utf8').trim();
              if (content === '' || content === '# ') {
                fs.unlinkSync(filePath);
                removed++;
                console.log(`  Removed empty file: ${file}`);
              }
            }
          }
          
          console.log(`  Removed ${removed} empty files`);
        }
        
        function standardizeLineEndings() {
          const files = findMarkdownFiles('.');
          let processed = 0;
          
          for (const file of files) {
            const content = fs.readFileSync(file, 'utf8');
            const normalized = content.replace(/\r\n/g, '\n').replace(/\r/g, '\n');
            
            if (content !== normalized) {
              fs.writeFileSync(file, normalized, 'utf8');
              processed++;
            }
          }
          
          console.log(`  Standardized line endings in ${processed} files`);
        }
        
        function removeTrailingWhitespace() {
          const files = findMarkdownFiles('.');
          let processed = 0;
          
          for (const file of files) {
            const content = fs.readFileSync(file, 'utf8');
            const cleaned = content.split('\n').map(line => line.trimEnd()).join('\n');
            
            if (content !== cleaned) {
              fs.writeFileSync(file, cleaned, 'utf8');
              processed++;
            }
          }
          
          console.log(`  Removed trailing whitespace from ${processed} files`);
        }
        
        function fixDuplicateHeaders() {
          const files = findMarkdownFiles('.');
          let fixed = 0;
          
          for (const file of files) {
            const content = fs.readFileSync(file, 'utf8');
            const lines = content.split('\n');
            const headers = new Map();
            let modified = false;
            
            for (let i = 0; i < lines.length; i++) {
              const match = lines[i].match(/^(#{1,6})\s+(.+)$/);
              if (match) {
                const level = match[1];
                const text = match[2].trim();
                const key = `${level}:${text}`;
                
                if (headers.has(key)) {
                  // Make header unique
                  lines[i] = `${level} ${text} (${headers.get(key) + 1})`;
                  modified = true;
                }
                
                headers.set(key, (headers.get(key) || 0) + 1);
              }
            }
            
            if (modified) {
              fs.writeFileSync(file, lines.join('\n'), 'utf8');
              fixed++;
            }
          }
          
          console.log(`  Fixed duplicate headers in ${fixed} files`);
        }
        
        function updateLastModified() {
          const files = findMarkdownFiles('.');
          const now = new Date().toISOString();
          
          for (const file of files) {
            const content = fs.readFileSync(file, 'utf8');
            
            // Update or add last modified timestamp
            if (content.includes('Last updated:')) {
              const updated = content.replace(/Last updated:.*$/m, `Last updated: ${now}`);
              fs.writeFileSync(file, updated, 'utf8');
            } else if (content.includes('---') && content.includes('---')) {
              // Add to frontmatter if it exists
              const withTimestamp = content.replace('---', `---\nlast_updated: ${now}\n---`);
              fs.writeFileSync(file, withTimestamp, 'utf8');
            }
          }
          
          console.log(`  Updated timestamps in ${files.length} files`);
        }
        
        function findMarkdownFiles(dir) {
          const files = [];
          
          function traverse(currentDir) {
            const items = fs.readdirSync(currentDir);
            
            for (const item of items) {
              const fullPath = path.join(currentDir, item);
              const stat = fs.statSync(fullPath);
              
              if (stat.isDirectory() && !item.startsWith('.') && item !== 'node_modules') {
                traverse(fullPath);
              } else if (item.endsWith('.md')) {
                files.push(fullPath);
              }
            }
          }
          
          traverse(dir);
          return files;
        }
        
        // Run the cleanup
        cleanupDocumentation();
        EOF
        
        chmod +x scripts/maintenance/cleanup-docs.js
        
    - name: Create documentation index updater
      run: |
        cat > scripts/maintenance/update-index.js << 'EOF'
        #!/usr/bin/env node
        
        const fs = require('fs');
        const path = require('path');
        
        /**
         * Documentation Index Updater
         * 
         * This script updates the documentation index with current file structure
         */
        
        function updateDocumentationIndex() {
          console.log('ğŸ“š Updating documentation index...');
          
          const docsDir = 'Docs';
          const indexPath = path.join(docsDir, 'README.md');
          
          if (!fs.existsSync(docsDir)) {
            console.log('âŒ Docs directory not found');
            return;
          }
          
          const structure = buildDocumentationStructure(docsDir);
          const indexContent = generateIndexContent(structure);
          
          fs.writeFileSync(indexPath, indexContent, 'utf8');
          console.log('âœ… Documentation index updated');
        }
        
        function buildDocumentationStructure(dir, relativePath = '') {
          const structure = {
            name: path.basename(dir) || 'Root',
            path: relativePath,
            children: [],
            files: []
          };
          
          const items = fs.readdirSync(dir).sort();
          
          for (const item of items) {
            const itemPath = path.join(dir, item);
            const stat = fs.statSync(itemPath);
            const itemRelativePath = path.join(relativePath, item);
            
            if (stat.isDirectory() && !item.startsWith('.')) {
              structure.children.push(buildDocumentationStructure(itemPath, itemRelativePath));
            } else if (item.endsWith('.md') && item !== 'README.md') {
              const content = fs.readFileSync(itemPath, 'utf8');
              const title = extractTitle(content) || item.replace('.md', '');
              
              structure.files.push({
                name: title,
                path: itemRelativePath,
                size: stat.size,
                lastModified: stat.mtime
              });
            }
          }
          
          return structure;
        }
        
        function extractTitle(content) {
          const match = content.match(/^#\s+(.+)$/m);
          return match ? match[1] : null;
        }
        
        function generateIndexContent(structure) {
          const now = new Date().toISOString().split('T')[0];
          
          return `# CLMS Documentation\n\n> Last updated: ${now}\n\n## ğŸ“– Overview\n\nThis directory contains comprehensive documentation for the Centralized Library Management System (CLMS).\n\n## ğŸ“š Documentation Structure\n\n${renderStructure(structure, 2)}\n\n## ğŸ” Quick Links\n\n- [Developer Quick Start Guide](DEVELOPER_QUICK_START_GUIDE.md)\n- [API Documentation](API_DOCUMENTATION.md)\n- [Deployment Guide](DEPLOYMENT_COMPREHENSIVE_GUIDE.md)\n- [Security Guide](SECURITY_COMPREHENSIVE_GUIDE.md)\n- [Performance Guide](PERFORMANCE_COMPREHENSIVE_GUIDE.md)\n\n## ğŸ› ï¸ Maintenance\n\nThis documentation is automatically maintained through CI/CD workflows. \nFor manual updates, see the [Documentation Maintenance Playbook](DOCUMENTATION_MAINTENANCE_PLAYBOOK.md).\n\n---\n\n*This index is automatically generated. Do not edit manually.*`;
        }
        
        function renderStructure(structure, indent) {
          let content = '';
          const spaces = ' '.repeat(indent);
          
          if (structure.files.length > 0) {
            for (const file of structure.files) {
              content += `\n${spaces}- [${file.name}](${file.path})`;
            }
          }
          
          if (structure.children.length > 0) {
            for (const child of structure.children) {
              content += `\n${spaces}### ${child.name}`;
              content += renderStructure(child, indent + 2);
            }
          }
          
          return content;
        }
        
        // Run the update
        updateDocumentationIndex();
        EOF
        
        chmod +x scripts/maintenance/update-index.js
        
    - name: Create orphaned files checker
      run: |
        cat > scripts/maintenance/check-orphans.js << 'EOF'
        #!/usr/bin/env node
        
        const fs = require('fs');
        const path = require('path');
        
        /**
         * Orphaned Files Checker
         * 
         * This script identifies documentation files that are not linked from any other files
         */
        
        function checkOrphanedFiles() {
          console.log('ğŸ” Checking for orphaned documentation files...');
          
          const allFiles = findMarkdownFiles('.');
          const fileLinks = new Map();
          const referencedFiles = new Set();
          
          // Collect all links from all files
          for (const file of allFiles) {
            const content = fs.readFileSync(file, 'utf8');
            const links = extractLinks(content);
            fileLinks.set(file, links);
            
            // Add referenced files to set
            for (const link of links) {
              if (link.endsWith('.md')) {
                referencedFiles.add(resolveLink(link, file));
              }
            }
          }
          
          // Find orphaned files
          const orphaned = [];
          for (const file of allFiles) {
            if (!referencedFiles.has(file) && !isEntryPoint(file)) {
              orphaned.push(file);
            }
          }
          
          // Generate report
          const report = generateOrphanReport(orphaned, allFiles.length);
          fs.writeFileSync('docs/reports/orphaned-files-report.md', report, 'utf8');
          
          console.log(`ğŸ“Š Found ${orphaned.length} potentially orphaned files`);
          console.log('ğŸ“„ Report saved to docs/reports/orphaned-files-report.md');
        }
        
        function findMarkdownFiles(dir) {
          const files = [];
          
          function traverse(currentDir) {
            const items = fs.readdirSync(currentDir);
            
            for (const item of items) {
              const fullPath = path.join(currentDir, item);
              const stat = fs.statSync(fullPath);
              
              if (stat.isDirectory() && !item.startsWith('.') && item !== 'node_modules') {
                traverse(fullPath);
              } else if (item.endsWith('.md')) {
                files.push(fullPath);
              }
            }
          }
          
          traverse(dir);
          return files;
        }
        
        function extractLinks(content) {
          const links = [];
          const linkRegex = /\[([^\]]+)\]\(([^)]+)\)/g;
          let match;
          
          while ((match = linkRegex.exec(content)) !== null) {
            links.push(match[2]);
          }
          
          return links;
        }
        
        function resolveLink(link, sourceFile) {
          if (link.startsWith('http')) return link;
          
          const sourceDir = path.dirname(sourceFile);
          const resolved = path.resolve(sourceDir, link);
          return path.normalize(resolved);
        }
        
        function isEntryPoint(file) {
          const entryPoints = [
            'README.md',
            'Docs/README.md',
            'Docs/DEVELOPER_QUICK_START_GUIDE.md',
            'Docs/API_DOCUMENTATION.md'
          ];
          
          return entryPoints.some(ep => file.endsWith(ep));
        }
        
        function generateOrphanReport(orphaned, totalFiles) {
          const now = new Date().toISOString();
          
          let content = `# Orphaned Documentation Files Report\n\n`;
          content += `> Generated on: ${now}\n\n`;
          content += `## Summary\n\n`;
          content += `- Total documentation files: ${totalFiles}\n`;
          content += `- Potentially orphaned files: ${orphaned.length}\n`;
          content += `- Coverage: ${((totalFiles - orphaned.length) / totalFiles * 100).toFixed(1)}%\n\n`;
          
          if (orphaned.length > 0) {
            content += `## Orphaned Files\n\n`;
            content += `The following files may not be linked from any other documentation:\n\n`;
            
            for (const file of orphaned) {
              content += `- \`${file}\`\n`;
            }
            
            content += `\n> **Note:** Some files may be intentionally standalone (e.g., templates, archives).\n`;
          } else {
            content += `## âœ… No Orphaned Files Found\n\n`;
            content += `All documentation files appear to be referenced from other files.\n`;
          }
          
          content += `\n---\n`;
          content += `*This report is generated automatically. Review manually before taking action.*\n`;
          
          return content;
        }
        
        // Run the check
        checkOrphanedFiles();
        EOF
        
        chmod +x scripts/maintenance/check-orphans.js
        
    - name: Create statistics generator
      run: |
        cat > scripts/maintenance/generate-stats.js << 'EOF'
        #!/usr/bin/env node
        
        const fs = require('fs');
        const path = require('path');
        
        /**
         * Documentation Statistics Generator
         * 
         * This script generates statistics about the documentation
         */
        
        function generateStatistics() {
          console.log('ğŸ“Š Generating documentation statistics...');
          
          const stats = collectStatistics();
          const report = generateStatsReport(stats);
          
          // Ensure reports directory exists
          fs.mkdirSync('docs/reports', { recursive: true });
          fs.writeFileSync('docs/reports/documentation-stats.json', JSON.stringify(stats, null, 2), 'utf8');
          fs.writeFileSync('docs/reports/documentation-stats.md', report, 'utf8');
          
          console.log('âœ… Statistics generated');
          console.log(`ğŸ“„ Reports saved to docs/reports/`);
        }
        
        function collectStatistics() {
          const files = findMarkdownFiles('.');
          const stats = {
            timestamp: new Date().toISOString(),
            totalFiles: files.length,
            totalSize: 0,
            directories: new Set(),
            fileTypes: {},
            largestFiles: [],
            oldestFiles: [],
            newestFiles: [],
            linkStats: {
              totalLinks: 0,
              brokenLinks: 0,
              externalLinks: 0
            },
            coverage: {
              hasReadme: false,
              hasApiDocs: false,
              hasDevGuide: false,
              hasDeployGuide: false
            }
          };
          
          const fileDetails = [];
          
          for (const file of files) {
            const stat = fs.statSync(file);
            const content = fs.readFileSync(file, 'utf8');
            const relativePath = path.relative('.', file);
            
            // Collect basic stats
            stats.totalSize += stat.size;
            stats.directories.add(path.dirname(relativePath));
            
            // File type
            const ext = path.extname(file);
            stats.fileTypes[ext] = (stats.fileTypes[ext] || 0) + 1;
            
            // Link stats
            const links = content.match(/\[([^\]]+)\]\(([^)]+)\)/g) || [];
            stats.linkStats.totalLinks += links.length;
            
            for (const link of links) {
              if (link.includes('http')) {
                stats.linkStats.externalLinks++;
              }
            }
            
            // Coverage checks
            if (relativePath.includes('README.md')) stats.coverage.hasReadme = true;
            if (relativePath.includes('API_DOCUMENTATION.md')) stats.coverage.hasApiDocs = true;
            if (relativePath.includes('DEVELOPER_QUICK_START_GUIDE.md')) stats.coverage.hasDevGuide = true;
            if (relativePath.includes('DEPLOYMENT')) stats.coverage.hasDeployGuide = true;
            
            fileDetails.push({
              path: relativePath,
              size: stat.size,
              modified: stat.mtime,
              links: links.length
            });
          }
          
          // Sort files by different criteria
          stats.largestFiles = fileDetails.sort((a, b) => b.size - a.size).slice(0, 10);
          stats.oldestFiles = fileDetails.sort((a, b) => a.modified - b.modified).slice(0, 10);
          stats.newestFiles = fileDetails.sort((a, b) => b.modified - a.modified).slice(0, 10);
          
          stats.directories = stats.directories.size;
          
          return stats;
        }
        
        function findMarkdownFiles(dir) {
          const files = [];
          
          function traverse(currentDir) {
            const items = fs.readdirSync(currentDir);
            
            for (const item of items) {
              const fullPath = path.join(currentDir, item);
              const stat = fs.statSync(fullPath);
              
              if (stat.isDirectory() && !item.startsWith('.') && item !== 'node_modules') {
                traverse(fullPath);
              } else if (item.endsWith('.md')) {
                files.push(fullPath);
              }
            }
          }
          
          traverse(dir);
          return files;
        }
        
        function generateStatsReport(stats) {
          let content = `# Documentation Statistics\n\n> Generated on: ${stats.timestamp}\n\n## ğŸ“Š Overview\n\n- **Total Files:** ${stats.totalFiles}\n- **Total Size:** ${(stats.totalSize / 1024).toFixed(1)} KB\n- **Directories:** ${stats.directories}\n- **Total Links:** ${stats.linkStats.totalLinks}\n- **External Links:** ${stats.linkStats.externalLinks}\n\n## ğŸ“ˆ Coverage\n\n`;
          const coverageScore = Object.values(stats.coverage).filter(Boolean).length / Object.keys(stats.coverage).length * 100;
          content += `- **Overall Coverage:** ${coverageScore.toFixed(0)}%\n- **README:** ${stats.coverage.hasReadme ? 'âœ…' : 'âŒ'}\n- **API Docs:** ${stats.coverage.hasApiDocs ? 'âœ…' : 'âŒ'}\n- **Dev Guide:** ${stats.coverage.hasDevGuide ? 'âœ…' : 'âŒ'}\n- **Deploy Guide:** ${stats.coverage.hasDeployGuide ? 'âœ…' : 'âŒ'}\n\n## ğŸ“‹ File Types\n\n`;
          
          for (const [ext, count] of Object.entries(stats.fileTypes)) {
            content += `- **${ext || 'no extension'}:** ${count}\n`;
          }
          
          content += `\n## ğŸ† Largest Files\n\n| File | Size |\n|------|------|\n`;
          for (const file of stats.largestFiles.slice(0, 5)) {
            content += `| ${file.path} | ${(file.size / 1024).toFixed(1)} KB |\n`;
          }
          
          content += `\n---\n*This report is generated automatically.*\n`;
          
          return content;
        }
        
        // Run the generation
        generateStatistics();
        EOF
        
        chmod +x scripts/maintenance/generate-stats.js
        
    - name: Run maintenance tasks
      run: |
        echo "ğŸ”§ Running documentation maintenance tasks..."
        
        # Create reports directory
        mkdir -p docs/reports
        
        # Run tasks based on input
        case "${{ github.event.inputs.task || 'all' }}" in
          "cleanup")
            echo "Running cleanup only..."
            node scripts/maintenance/cleanup-docs.js
            ;;
          "update-index")
            echo "Updating index only..."
            node scripts/maintenance/update-index.js
            ;;
          "check-orphans")
            echo "Checking orphaned files only..."
            node scripts/maintenance/check-orphans.js
            ;;
          "generate-stats")
            echo "Generating statistics only..."
            node scripts/maintenance/generate-stats.js
            ;;
          "all"|*)
            echo "Running all maintenance tasks..."
            node scripts/maintenance/cleanup-docs.js
            node scripts/maintenance/update-index.js
            node scripts/maintenance/check-orphans.js
            node scripts/maintenance/generate-stats.js
            ;;
        esac
        
    - name: Commit changes
      if: github.event_name == 'schedule'
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add changes
        git add Docs/ docs/reports/ scripts/maintenance/
        
        # Check if there are changes to commit
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ğŸ¤– Automated documentation maintenance [skip ci]"
          git push
        fi
        
    - name: Upload maintenance reports
      uses: actions/upload-artifact@v4
      with:
        name: documentation-maintenance-reports
        path: docs/reports/
        retention-days: 30